<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook50-profile.xsl"
                 type="text/xml" 
                 title="Profiling step"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"
    xml:id="advanced.topics.optimizing.scalability">
 <title>Optimization and Scalability</title>

 <sect1 xml:id="optimizing.apache_tomcat">
  <title>Optimizing Apache and Tomcat</title>

  <warning>
   <title>Altering Apache and Tomcat Parameters</title>
   <para>
    Apache and Tomcat Parameters
    should only be modified with support or consulting as these
    parameters can have severe and catastrophic performance impacts on your
    server when improperly adjusted. SUSE will not be able to provide support
    for catastrophic failure when these advanced parameters are modified
    without consultation. Tuning values for Apache httpd and Tomcat requires
    that you align these parameters with your server hardware. Furthermore
    testing of these altered values should be performed within a test
    environment.
   </para>
  </warning>

  <sect2>
   <title>Apache's httpd MaxClients Parameter</title>
   <para>
    The <parameter class="option">MaxClients</parameter> setting determines the
    number of Apache httpd processes, and thus limits the number of client
    connections that can be made at the same time (SUSE Manager uses the
    pre-fork MultiProcessing Modules). The default value for
    <parameter class="option">MaxClients</parameter> in SUSE Manager is 150. If
    you need to set the <parameter class="option">MaxClients</parameter> value
    greater than 150, Apache httpd's ServerLimit setting and Tomcat's
    <parameter
                class="option">maxThreads</parameter> must also
    be increased accordingly (see below).
   </para>
   <warning>
    <para>
     The Apache httpd <parameter class="option">MaxClients</parameter>
     parameter must always be less or equal than Tomcat's
     <parameter class="option"
                    >maxThreads</parameter>
     parameter!
    </para>
   </warning>
   <para>
    If the <parameter class="option">MaxClients</parameter> value is reached
    while the software is running, new client connections will be queued and
    forced to wait, this may result in timeouts. You can check the Apache
    httpd's <filename>error.log</filename> for details:
   </para>
<screen>[error] Server reached MaxClients setting, consider increasing the MaxClients setting</screen>
   <para>
    The default <parameter class="option">MaxClients</parameter> parameter can
    be overridden on SUSE Manager by editing the
    <filename>server-tuning.conf</filename> file located at
    <systemitem>/etc/apache2/</systemitem>.
   </para>
   <para>
    Example <filename>server-tuning.conf</filename> file:
   </para>
<screen># prefork MPM
   &lt;IfModule prefork.c&gt;
           # number of server processes to start
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#startservers
           StartServers         5
           # minimum number of server processes which are kept spare
           # http://httpd.apache.org/docs/2.2/mod/prefork.html#minspareservers
           MinSpareServers      5
           # maximum number of server processes which are kept spare
           # http://httpd.apache.org/docs/2.2/mod/prefork.html#maxspareservers
           MaxSpareServers     10
           # highest possible MaxClients setting for the lifetime of the Apache process.
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#serverlimit
           ServerLimit        150
           # maximum number of server processes allowed to start
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#maxclients
           MaxClients         150
           # maximum number of requests a server process serves
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#maxrequestsperchild
           MaxRequestsPerChild  10000
   &lt;/IfModule&gt;</screen>
  </sect2>

  <sect2>
   <title>Tomcat's maxThreads Parameter</title>
   <para>
    Tomcat's <parameter class="option">maxThreads</parameter> represents the
    maximum number of request processing threads that it will create. This
    value determines the maximum number of simultaneous requests that it is
    able to handle. All HTTP requests to the SUSE Manager server
    (from clients, browsers, XMLRPC API scripts, etc.) are handled by Apache
    httpd, and some of them are routed to Tomcat for further processing. It is
    thus important that Tomcat is able to serve the same amount of simultaneous
    requests that Apache httpd is able to serve in the worst case. The default
    value for SUSE Manager is 200 and should always be equal or greater than
    Apache httpd's <parameter class="option">MaxClients</parameter>. The
    <parameter class="option"
                >maxThreads</parameter> value is
    located within the <filename>server.xml</filename> file located at
    <systemitem>/etc/tomcat/</systemitem>.
   </para>
   <para>
    Example relevant lines in <filename>server.xml</filename>:
   </para>
<screen>&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" URIEncoding="UTF-8" address="127.0.0.1" maxThreads="200" connectionTimeout="20000"/&gt;
&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" URIEncoding="UTF-8" address="::1" maxThreads="200" connectionTimeout="20000"/&gt;</screen>
   <note>
    <title>Tuning Notes</title>
    <para>
     When configuring Apache httpd's
     <parameter class="option">MaxClients</parameter> and Tomcat's
     <parameter class="option"
                >maxThreads</parameter>
     parameters you should also take into consideration that each HTTP
     connection will need one or more database connections. If the RDBMS is not
     able to serve an adequate amount of connections, issues will arise.
     See the following equation for a rough calculation of the needed amount of
     database connections:
    </para>
<screen language="python">((3 * java_max) +  apache_max + 60)</screen>
    <para>
     Where:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       3 is the number of Java processes the server runs with pooled
       connections (Tomcat, Taskomatic and Search)
      </para>
     </listitem>
     <listitem>
      <para>
       java_max is the maximum number of connections per Java pool (20
       by default, changeable in <filename>/etc/rhn/rhn.conf</filename>
       via the hibernate.c3p0.max_size parameter)
      </para>
     </listitem>
     <listitem>
      <para>
       apache_max is Apache httpd's
       <parameter class="option">MaxClients</parameter>
      </para>
     </listitem>
     <listitem>
      <para>
       60 is the maximum expected number of extra connections for local
       processes and other uses
      </para>
     </listitem>
    </itemizedlist>
   </note>
  </sect2>
 </sect1>
 <!-- ============================================================ -->
 <sect1 xml:id="optimizing.big">
  <title>Big Scale Deployment (1000 Minions or More)</title>
  <para>
   In the following sections find considerations about a big scale
   deployment.  In this context, a big scale compromises 1000 minions or
   more.
  </para>
  <sect2 xml:id="optimizing.big.general">
  <title>General Recommendations</title>

  <para>
   &suse; recommends the following in a big scale &susemgr; deployment:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     &susemgr; servers should have at least 8 recent &x86; cores, 32 GiB
     of RAM, and, most important, fast I/O devices such as at least an
     SSD (2 SSDs in RAID-0 are strongly recommended).
    </para>
   </listitem>
   <listitem>
    <para>
     Proxies with many minions (hundreds) should have at least 2 recent
     &x86; cores and 16 GiB of RAM.
    </para>
   </listitem>
   <listitem>
    <para>
     Use one &susemgrproxy; per 500-1000 clients.  Keep into account
     that download time depends on network capacity.  Here is a rough
     example calculation with physical link speed of 1 GB/s:
    </para>

<screen> 400 Megabytes  *        3000       /      119 Megabyte/s        / 60
= 169 Minutes</screen>
<para>This is:</para>
    <screen
>Size of updates * Number of minions / Theoretical download speed / 60</screen>
   </listitem>
   <listitem>
    <para>
     Depending on hardware you can accept hundreds of minion keys.
    </para>
   </listitem>
   <listitem>
    <para>
     Plan time for onboarding minions&mdash;at least one hour per 1000 minions.
    </para>
   </listitem>
   <listitem>
    <para>
     It is not recommended onboarding more than approx. 1000 minions
     directly to the &susemgr; server&mdash;proxies should be used
     instead. This is because every minion can use up to 3 TCP
     connections simultaneously, and too many TCP connections can cause
     performance issues.
    </para>
   </listitem>
   <listitem>
    <para>
     If the following error appears in output of
     <command>dmesg</command>, you probably have an excessive number of
     minions attached to a single &susemgr; server or proxy for the ARP
     cache to contain all of their addresses:
    </para>

    <screen>kernel: neighbour table overflow</screen>

    <para>
     In that case, increase the ARP cache values via
     <systemitem>sysctl</systemitem>, for example, by adding the
     following lines to <filename>/etc/sysctl.conf</filename>:
    </para>
<screen>net.ipv4.neigh.default.gc_thresh1 = 4096
net.ipv4.neigh.default.gc_thresh2 = 8192
net.ipv4.neigh.default.gc_thresh3 = 16384
net.ipv4.neigh.default.gc_interval = 60
net.ipv4.neigh.default.gc_stale_time = 120</screen>
   </listitem>
  </itemizedlist>
  <tip>
   <title>Start Small and Scale Up</title>
   <para>
    Always start small and scale up gradually. Keep the server monitored
    in order to identify possible issues early.
   </para>
  </tip>
  </sect2>
  <sect2 xml:id="optimizing.big.tuning">
   <title>Tuning Proposals</title>

   <para>
    &suse; proposes the following tuning settingsin a big scale &susemgr;
    deployment:
   </para>

   <itemizedlist>
    <listitem>
     <para>
      Increase Tomcat memory to face a long queue of Salt return
      results.  Items in the Salt return queue might accumulate in a
      short time: Set 8 GiB instead of the current default 1 GiB.
     </para>
    </listitem>
    <listitem>
     <para>
      Several RHN parameters should be changed from their defaults:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        The number of Taskomatic workers should be increased, and thus
        parallelizing work on a high number of separate jobs
        (onboarding, staging).
       </para>
      </listitem>
      <listitem>
       <para>
        Quartz should check for runnable jobs more frequently to reduce
        latency (onboarding, staging, Action execution).
       </para>
      </listitem>
      <listitem>
       <para>
        Tomcat's Salt return result workers should be increased, and
        thus parallelizing work on a high number of Salt return results
        (patching).
       </para>
      </listitem>
      <listitem>
       <para>
        The number of PostgreSQL connections available to Java
        applications (Tomcat, Taskomatic) should increase
        accordingly. Otherwise extra workers will starve waiting for a
        connection.
       </para>
      </listitem>
      <listitem>
       <para>
        Salt's presence ping timeouts should be increased because
        responses might come back later than the defaults.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
    <listitem>
     <para>
      Salt master worker threads should be increased to 100 from 15, and
      thus parallelizing more requests (otherwise Tomcat and Taskomatic
      workers will starve waiting for the API to do something).
     </para>
    </listitem>
    <listitem>
     <para>
      Increasing the number of Salt master worker threads more requires
      more RAM and does not bring benefits.  Apache maximum request time
      should be increased.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 
</chapter>
